- Topic: The Lagrangian, The Lagrange Dual Function
- Last revised: Feb. 20, 2023

---

# The Lagrangian

Consider an optimization problem in the standard form (Boyd 2009, Eq. (4.1))

$$\begin{aligned}\min\ &f_0(x)\\\text{s. t. }&f_i(x)\leq0,\quad i=1,\dots,m\\&h_i(x)=0,\quad i=1,\dots,p,\end{aligned}$$

in a real-valued number space. Note that this optimization is not necessarily convex. The *Lagrangian (multiplier)* is defined as

$$\mathcal{L}(x,\lambda,v)=f_0(x)+\sum_{i=1}^{m}\lambda_if_i(x)+\sum_{i=1}^{p}\nu_ih_i(x),$$

mapping $\mathbb{R}^n\times\mathbb{R}^m\times\mathbb{R}^p$ input to a scalar output. The domain of function $\mathcal{L}(\cdot)$ is $\textbf{dom}\mathcal{L}=\mathcal{D}\times\mathbb{R}^m\times\mathbb{R}^p$, where $\mathcal{D}$ is the domain of $x$. The vector $\lambda=[\lambda_1,\dots,\lambda_m]^T$ and $\nu=[\nu_1,\dots,\nu_p]^T$ are called the *dual variables*, while $x$ is *primal variable*.

The lagrangian considers the constraints as weighted factors, which are added with the original objective function.

## Extension to real-valued function with complex-valued variables 

Note that the Lagrangian can be extended to the *complex-valued number space*. Basically speaking, we should consider the Lagrangian real-valued. Most importantly, in generality the objective function $f_0(x)$ should return a real-valued scalar, so that the function can be minimized or maximized. Complex-valued numbers can not be ordered. The dual variable $\lambda$ related to the inequality constrains should be real-valued, since the inequality returns also real value so that it can be compared with zero. Basically there are no constraint on $\nu$ whether it is real or complex, since the equality constraint equals zero.

### Example 1

Consider the following optimization problem where $x\in\mathbb{C}$, $x^*$ is the conjugate of $x$,

$$\begin{aligned}
   \min\quad & x^*x\\
   s.t.\quad & x=x^*+i. 
\end{aligned}$$

Note that this is a convex optimization problem, since the objective function ($x^HAx$ is convex when $A$ is positive semi-definite) and the constraint are convex. It is easy to see that the Slater's condition fulfills, for example, $x=i/2$ makes sure the equality exists (note that if there are inequality constrains, they must be strictly inequal). Therefore, strong duality satisfies. The Lagrangian with a dual variable $\nu\in\mathbb{C}$ can be written as

$$\mathcal{L}(x,\nu)=x^*x+\nu(x-x^*-i).$$

Taking the partial derivatives with respect to $x$ and $x^*$ by using Wirtinger Derivative, we have

$$\begin{aligned}
   \frac{\partial\mathcal{L}}{\partial x}&=x^*+\nu,\\
   \frac{\partial\mathcal{L}}{\partial x^*}&=x-\nu.
\end{aligned}$$

These partial derivatives should be zero for optimal primal variable $x$, and hence by combining them we have $x+x^*=0$. With $x-x^*-i=0$, we have $2x-i=0$. As a result, $x=i/2$.

# The Definition of Lagrange Dual Function

For the Lagrangian, there are three vector variables, $x$, $\lambda$ and $\nu$. If $x$ is considered to be known to be the point that the Lagrangian is minimum over $x$, only those dual variables are left. It is interesting to find out the relation of the origin optimization problem with respect to $x$ and the formulated optimization problem with respect to $\lambda$ and $\nu$.

The *Lagrangian dual function* is defined with only the dual variables

$$g(\lambda,\nu)=\inf_{x\in\mathcal{D}}\mathcal{L}(x,\lambda,\nu)=\inf_{x\in\mathcal{D}}\left(f_0(x)+\sum_{i=1}^{m}\lambda_if_i(x)+\sum_{i=1}^{p}\nu_ih_i(x)\right),$$

where $\lambda\in\mathbb{R}^m$ and $\nu\in\mathbb{R}^p$.

# Properties

1. When the Lagrangian is unbounded below in $x$, $g(\lambda,\nu)=-\infty$.
2. The Lagrangian dual function is *dual feasible* if $\lambda\succeq0$ and $g(\lambda,\nu)>-\infty$.
3. $g(\lambda,\nu)$ is concave in $(\lambda,\nu)$ since it is the pointwise infimum of a family of affine functions of $(\lambda,\nu)$. That's to say, for every $\lambda_i$ and $\nu_i$, we should the smallest values of $x$. This is true even when the original optimization problem is not convex.
    ![piecewise-infimum-is-concave](../image/5.1.2_piecewise_infimum_is_concave.png)

    Fig: Piecewise infimum is a concave function.
4. The dual function is a lower bound of the optimal value $p^*$ of the original optimization problem, i.e. $g(\lambda,\nu)\leq p^*$.

Property 3 is important. And it is also easy to verify. If $\tilde{x}$ is the optimal point, then $f_i(\tilde{x})\leq0$ and $h_i(\tilde{x})=0$, and without loss of generality, $\lambda\geq0$. Then we have $\sum_{i=1}^{m}\lambda_if_i(\tilde{x})+\sum_{i=1}^{P}\nu_ih_i(\tilde{x})\leq0$. Finally, we have

$$\mathcal{L}(\tilde{x},\lambda,\nu)=f_0(\tilde{x})+\sum_{i=1}^{m}\lambda_if_i(\tilde{x})+\sum_{i=1}^{p}\nu_ih_i(\tilde{x})\leq f_0(\tilde{x}).$$

Therefore, we have

$$g(\lambda,\nu)=\inf_{x\in\mathcal{D}}\mathcal{D}(x,\lambda,\nu)\leq\mathcal{L}(\tilde{x},\lambda,\nu)\leq f_o(\tilde{x})=p^*.$$

The Lagrange dual function must be lower the optimal value (minimum of the objective function) of the original optimization problem. On other words, the Lagrange dual function achieves always better performance of the original optimization problem. This is because we introduce some extra terms from the constraints of the original problem in Lagrangian.

# The Lagrangian dual function is a linear approximation of an infinitely-hard displeasure function